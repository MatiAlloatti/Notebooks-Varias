{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matías Alloatti - 2020\n",
    "This notebook was done compiling tutorials from:\n",
    "1. https://pytorch.org/tutorials/\n",
    "2. https://deeplizard.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "### Neural networks can be constructed using the `torch.nn` package.\n",
    "\n",
    "Now that you had a glimpse of `autograd`, the library `nn` depends on `autograd` to define models and differentiate them. An `nn.Module` contains layers, and a method `forward(input)` that returns the `output`.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "   - Define the neural network that has some learnable parameters (or weights)\n",
    "   - Iterate over a dataset of inputs\n",
    "   - Process input through the network\n",
    "   - Compute the loss (how far is the output from being correct)\n",
    "   - Propagate gradients back into the network’s parameters\n",
    "   - Update the weights of the network, typically using a simple update rule: `weight = weight - learning_rate * gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just have to define the `forward` function; The `backward` function (where gradients are computed) is automatically defined for you using `autograd`. You can use any of the Tensor operations in the `forward` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# The nn.Module class is used to create a NN, it's the base class for all neural network modules.\n",
    "# Your models should also subclass this class.\n",
    "class Net(nn.Module):\n",
    "# The __init__() method initializes an instance and is used to create the needed layers\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # nn.Conv2d() applies a 2d convolution \n",
    "        # 2d convolution layer with 1 input image channel (color), 6 output channels (filters), and 3x3 convolution kernels:\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)        # defaults: stride=1, padding=0\n",
    "        # 2d convolution layer with 6 input channels, 16 output channels (filters), and 3x3 convolution kernels:\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3) \n",
    "        # nn.Liear() applies a linear transformation: y = Wx + b takes n_features, out_features, and bias=True\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)          # \n",
    "        self.fc3 = nn.Linear(84, 10)           # \n",
    "\n",
    "# The forward() method creates the structure of the network and through its layers transforms x:\n",
    "    def forward(self, x):\n",
    "        # F.max_pool2d() applies maxpooling with a definite kernel_size, stride, and padding (defaults: stride=None, padding=0)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # max pooling over a (2, 2) window \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # you can specify just a single number if the size is square\n",
    "        x = x.view(-1, self.num_flat_features(x))  # reshaping of x (flattening)\n",
    "        x = F.relu(self.fc1(x))                    # applies a nonlinearity (relu) to linear transform (fc1)\n",
    "        x = F.relu(self.fc2(x))                    # non linear activation (relu) after linear transform (fc2)\n",
    "        x = self.fc3(x)                            # last linear transformation (fc3)\n",
    "        return x\n",
    "\n",
    "# auxiliary method to flatten features:\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]                        # takes all dimensions except the batch dimension\n",
    "        num_features = 1                           # num_features will capture the total number of features\n",
    "        for s in size:                             # multiplies all dimensions in size to get total features\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len() of parameter list: 10\n",
      "conv1's weights size: torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The learnable parameters of a model are returned by net.parameters():\n",
    "params = list(net.parameters())\n",
    "print('len() of parameter list:', len(params))\n",
    "print(\"conv1's weights size:\", params[0].size())  # conv1's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0747, -0.0454,  0.1177, -0.0867,  0.1047, -0.0502, -0.0487,  0.0826,\n",
      "         -0.0449,  0.0971]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Let’s try a random 32x32 input. Note: expected input size of this net (LeNet) is 32x32. \n",
    "# To use this net on the MNIST dataset, please resize the images from the dataset to 32x32.\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Note: `torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample. \n",
    "\n",
    "For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width. If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.\n",
    "\n",
    "---\n",
    "\n",
    "Before proceeding further, let’s recap all the classes you’ve seen so far:\n",
    "\n",
    "- `torch.Tensor` - A multi-dimensional array with support for autograd operations like `backward()`. Also holds the gradient w.r.t. the tensor.\n",
    "- `nn.Module` - Neural network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "- `nn.Parameter` - A kind of `Tensor`, that is automatically registered as a parameter when assigned as an attribute to a `Module`.\n",
    "- `autograd.Function` - Implements forward and backward definitions of an autograd operation. Every `Tensor` operation creates at least a single `Function` node that connects to functions that created a `Tensor` and encodes its history.\n",
    "\n",
    "At this point, we covered:\n",
    "- Defining a neural network\n",
    "- Processing inputs and calling backward\n",
    "\n",
    "Now, a break reviewing CNNs concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs: terminology, Output Size Formula and more\n",
    "### Terminology:\n",
    "CNNs (Convolutional Neural Networks) have convolutional layers. They're really useful for detecting patterns in images.\n",
    "- Convolutional layer: applies a convolution operation with certain ammount of filters.\n",
    "- Convolutional filter: a filter is a small matrix initialized with random numbers that convolves (slides) through the input data and performs a dot.product with it.\n",
    "- Convolutional kernel: another name for filters, they have a certain size\n",
    "- Output channel `nn.Conv2d(out_channels)`: out_channels are the result of applying each filter/kernel.\n",
    "- Feature maps: another way to refer to the output channels. This is due to the fact that the pattern detection that emerges as the weights are updated represent features like edges and other more sophisticated patterns.\n",
    "- The filters are the Weight Tensors of the layer and they are used to convolve the Input Tensor and the result is the output channel.\n",
    "\n",
    "### Algorithm:\n",
    "    Color channels are passed in.\n",
    "    Convolutions are performed using the weight tensor (filters).\n",
    "    Feature maps are produced and passed forward.\n",
    "    \n",
    "Conceptually, we can think of the Weight Tensors as being distinct. However, what we really have in code is a single Weight Tensor that has an `out_channels` (filters) dimension. We can see this by checking the shape of the weight tensor: `self.conv1.weight.shape` This tensor’s shape is given by: [number of filters, number of input channels, filter height, filter width]\n",
    "\n",
    "### Output Size Formula:\n",
    "Let's have a look at the formula for computing the output size of the tensor after performing convolutional and pooling operations.\n",
    "###### CNN Output Size Formula (Square)\n",
    "With an $n×n$ input, a $f×f$ filter, a padding of $p$ and a stride of $s$. The output size $O$ is given by this formula: $$O=\\frac{n−f+2p}{s}+1$$\n",
    "\n",
    "This value will be the height and width of the output. However, if the input or the filter isn't a square, this formula needs to be applied twice, once for the width and once for the height.\n",
    "###### CNN Output Size Formula (Non-Square)\n",
    "With an $n_{h}×n_{w}$ input, a $f_{h}×f_{w}$ filter, a padding of $p$ and a stride of $s$.\n",
    "\n",
    "The height of the output size $O_{h}$ is given by this formula: $$O_{h}=\\frac{n_{h}−f_{h}+2p}{s}+1$$\n",
    "\n",
    "The width of the output size O_{w} is given by this formula: $$O_{w}=\\frac{n_{w}−f_{w}+2p}{s}+1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Other example of CNN (input tensor size: [1, 1, 28, 28] --> [batch size, color channels, height, width]):\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2d convolutions:\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)  # bigger kernels than Net (former) CNN\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5) # bigger kernels and less out_channels than Net\n",
    "        # linear transformations:\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = t                                        # (1) input layer (identity function)\n",
    "        t = self.conv1(t)                            # (2) hidden conv layer\n",
    "        t = F.relu(t)                                # relu activation\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2) # 2d max pooling\n",
    "        t = self.conv2(t)                            # (3) hidden conv layer\n",
    "        t = F.relu(t)                                # relu activation\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2) # 2d max pooling  \n",
    "        t = t.reshape(-1, 12 * 4 * 4)                # (4) hidden linear layer. This line flattens the tensor resulting in Size=([1,192])\n",
    "        t = self.fc1(t)                              # linear transformation\n",
    "        t = F.relu(t)                                # relu activation\n",
    "        t = self.fc2(t)                              # (5) hidden linear layer\n",
    "        t = F.relu(t)                                # relu activation\n",
    "        t = self.out(t)                              # (6) output layer\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t\n",
    "\n",
    "net2 = Net2()\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU activation function:\n",
    "The call to the `F.relu()` function removes any negative values and replaces them with zeros. We can verify this by checking the `Tensor.min()` of the tensor before and after the call.\n",
    "\n",
    "The `relu()` function can be expressed mathematically as: \n",
    "$$f(x)=\\begin{cases} 0 & if & x<0 \\\\ x & if & x≥0\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The max pooling operation\n",
    "The pooling operation reduces the shape of our tensor further by extracting the maximum value from each 2x2 location within our tensor. To apply a 2D max pooling over an input signal composed of several input planes we use: `torch.nn.MaxPool2d()`. It takes: `kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False` as posible inputs. \n",
    "\n",
    "The parameters `kernel_size, stride, padding, dilation` can either be:\n",
    "- an `int` (same value for height and width)\n",
    "- a `tuple` of two ints (1st int for height, 2nd for width)\n",
    "\n",
    "If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points. Dilation controls the spacing between the kernel points. This [link](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md) has a nice visualization of what dilation, padding and stride do.\n",
    "\n",
    "Now, we continue with pytorch tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target. There are several different [loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions) under the nn package . A simple loss is: `nn.MSELoss()` which computes the mean-squared error between the input and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9672, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you follow loss in the backward direction, using its `.grad_fn` attribute, you will see a graph of computations that looks like this:\n",
    "\n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "          -> view -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss\n",
    "\n",
    "So, when we call `loss.backward()`, the whole graph is differentiated wrt the loss, and all Tensors in the graph that has `requires_grad=True` will have their `.grad` Tensor accumulated with the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7fc80a81fdd0>\n",
      "<AddmmBackward object at 0x7fc80a817550>\n",
      "<AccumulateGrad object at 0x7fc80a817910>\n"
     ]
    }
   ],
   "source": [
    "# Following a few steps backward for ilustration:\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop\n",
    "\n",
    "To backpropagate the error all we have to do is to `loss.backward()`. You need to clear the existing gradients though, else gradients will be accumulated to existing gradients.\n",
    "\n",
    "Now we shall call `loss.backward()`, and have a look at conv1’s bias gradients before and after the backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0057,  0.0105,  0.0310, -0.0020,  0.0147, -0.0188])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()                            # zeroes the gradient buffers of all parameters\n",
    "print('conv1.bias.grad before backward:')   \n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward:')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Later:\n",
    "\n",
    "The neural network package contains various modules and loss functions that form the building blocks of deep neural networks. A full list with documentation is [here](https://pytorch.org/docs/stable/nn.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the weights\n",
    "The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n",
    "\n",
    "    weight = weight - learning_rate * gradient\n",
    "    \n",
    "We can implement this using simple Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: `torch.optim` that implements all these methods. Using it is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim                      # import package\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01) # create optimizer\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()                            # zero the gradient buffers\n",
    "# Gradient buffers had to be manually set to zero using optimizer.zero_grad(). \n",
    "# This is because gradients are accumulated as explained in the Backprop section.\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()                                 # Does the update, Easy ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
